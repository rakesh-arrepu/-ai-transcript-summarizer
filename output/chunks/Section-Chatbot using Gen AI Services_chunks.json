[ {
  "chunk_id" : "1",
  "title" : "Chunk 1",
  "text" : "OCI GEN AI Agent\n\nHello, and welcome to this lesson on Oracle Generative AI Agents, a part of OCI Generative AI course. As we have seen, OCI Generative AI service and RAG in the earlier lessons, we will now discuss about Oracle's Generative AI Agent service.\n\nSo let's understand what this service is all about. Generative AI Agents is a fully managed service that combines the power of large language models with an intelligent retrieval system aimed at creating contextually relevant answers by searching your knowledge base. For example, we ask this AI agent to book me a flight to Vegas as well as a room at Hilton Hotel.\n\nThe agent will understand and interpret the query, determine what next steps are to be taken, retrieves data from the data stores, and finally gives a response or executes an action. In this case, you can see that the response is your travel is booked, most likely after performing the necessary actions.\n\nSo overall, agents are applications of large language models, packaged and validated and ready to use out of the box. OCI Generative AI Agents supports several ways to onboard your data, where you and your customers can interact with your data using a chat interface or an API.\n\nLet's talk about the overall architecture. So the journey begins with the interface. This is the point where the user interacts with the AI agent. It can be a chatbot, a web app, a voice interface, or any application where the user inputs a query or a command. The system feeds various inputs to large language model.\n\nSo first one is short/long term memory. It can provide context from past interactions, enabling continuity and relevance in conversations. Tools-- you can integrate different external tools, for example, different APIs, databases, or third-party systems to enhance the model's capabilities.\n\nAnd then there is prompt. It contains the specific query or task provided by the user guiding the AI on how to generate responses. And at the heart of the system, you can see that there is large language model. It basically performs four key operations, reasoning, acting, persona, and planning.\n\nSo in reasoning, it analyzes the input to generate logical and coherent responses. For acting, it determines actions based on the task, for example, whether it's about querying databases or calling different APIs. Persona is maintaining a consistent tone, style, and behavior aligned with the brand or use case. And fourth, planning, that is strategically organizing responses or actions, especially in multi-step workflows.\n\nThe LLM can also access external knowledge bases, such as databases or document repositories, to enrich its responses with accurate and up-to-date information. You have already seen a use case of RAG. This allows the agent to go beyond just its internal training data.\n\nAnd based on all the processed inputs, reasoning, and integrated knowledge, the LLM generates a response. And this response is tailored to the query and context provided by the user. The output generated by the AI agent can feed back into its short term memory, enabling improved responses in ongoing interactions.\n\nSo you can say that overall, there is a feedback loop as well. And this architecture ensures that the Oracle Generative AI Agent delivers highly intelligent contextual and actionable responses by leveraging user inputs, external tools, and robust reasoning capabilities. It is designed for scalability, adaptability, and efficiency in enterprise applications. So overall, this AI agent is an LLM-based application, which can perform complex tasks on its own, mimic chain of thought process, can automate different use cases, and utilize existing data to complete actions or to provide a response.\n\nWe will now explore the core concepts that empowered the agents to deliver intelligent and, again, contextually relevant interactions. At the heart of OCI Generative Agents lies the generative AI model. This is a large language model, as we saw earlier in the architecture.\n\nIt is trained on vast data sets to generate human-like text. It processes, new inputs to produce again coherent and contextually appropriate responses, enabling natural language understanding and generation.\n\nNext one is the agent itself. This is an autonomous system built upon the LLM. It comprehends and generates text while facilitating natural language interactions. OCI supports RAG agents which connect to data sources, retrieve pertinent information, and enhance model responses with this data, which ensures more accurate and relevant outputs.\n\nWhen using RAG agents, models need to perform with high answerability and groundedness. So answerability is where the model can generate relevant responses to different user queries. And groundedness, on the other hand, is that the model-generated responses should be tracked to different data sources.\n\nTo function effectively, an agent accesses data through a structured hierarchy. And the first one is data source, then data store, and the other one is knowledge base. So let's discuss about the data store first. The repository where data resides, such as object storage buckets or databases. That is what we call as data store.\n\nThe data source, it provides connection details to the data store, enabling the agent to access and retrieve data. And the knowledge base is basically the vector storage system that ingests data from the data source, organizing it for efficient retrieval and use by the agent. And this structure ensures that agents can seamlessly access and utilize the necessary information to generate informed responses.\n\nAgain, Oracle provides multiple data options to make your information accessible to generative AI agents. The first one is object storage data. You can directly upload data files to OCI Object Storage, allowing the service to automatically ingest the data. And again, this is a service managed option. That means the service takes care of this ingestion part.\n\nSecond one is OpenSearch data, where you can bring your own ingested and indexed data from OCI Search with OpenSearch for the agents to utilize. And the third one is Oracle Database vector store. You can again bring your own vector embeddings from an Oracle Base Database 23ai or an Autonomous Database 23ai vector store to the generative AI agents.\n\nIn this course, we will discuss about the object storage and Oracle Database 23ai options. As we earlier discussed, this data ingestion is the process of extracting data from source documents, transforming it into a structured format suitable for analysis and storing it within the knowledge base. This step is crucial for preparing the raw data so that the agent can efficiently access and utilize it during interactions.\n\nLet's continue to some more concepts. The first one is session. A session represents the interactive conversation initiated by a user, maintaining context throughout the exchange to ensure coherent and relevant responses.",
  "source_file" : "Section-Chatbot using Gen AI Services.txt",
  "start_line" : 0,
  "end_line" : 0
}, {
  "chunk_id" : "2",
  "title" : "Chunk 2",
  "text" : "The second one is agent endpoint. It is a specific access point that enables the agent to communicate with external systems or services. It also facilitates the exchange of data, allowing the agent to retrieve or send information as needed to perform its functions effectively.\n\nThere is a feature called trace. This tracks and displays the history of a chat conversation, including both user prompts and the agent's responses. This functionality is valuable for monitoring interactions, understanding decision making process, and ensuring transparency in the agent's operations.\n\nOn the other hand, citation refers to the source of information used in the agent's response. The RAG agent provides citations for each response, including details like title, external path, document ID, and page numbers. And this ensures that users can trace responses back to their original source, enhancing trust and accountability.\n\nThe last one is content moderation. So it is a feature designed to detect and filter out harmful content from both user prompts and generated responses. It focuses on identifying and mitigating various types of harm, including hate and harassment, self-inflicted harm, ideological harm, and exploitation, ensuring that interactions remain safe and respectful. Keep in mind, moderation can be applied to just user prompt or generated response, or to both.\n\nWe already know that we upload data files to OCI Object Storage and let Generative AI agents automatically ingest the data. Now, we will see some guidelines on using object storage as data source.\n\nSo you can, again, as I mentioned, upload your data as files to an object storage bucket. Each data source is associated with a single bucket. Keep in mind again, only one bucket allowed per data source. The service supports only PDF and text file formats, and each file must not exceed 100 MB in size. The PDF files can include images, charts, and reference tables, but these elements again must not exceed 8 MBA.\n\nMoving on, you have to ensure that charts are two dimensional with labeled axes. The model can interpret and answer questions about these charts without any additional preparation. You can also use reference tables with several rows and columns. The agent can read and interpret such tables effectively.\n\nAll hyperlinks present in the PDF documents are extracted and displayed as clickable links in the chat responses. And if your data is not ready yet, you can always create an empty folder for the data source and populate it later. This approach basically allows you to set up the data source in advance and ingest data once it's available. By following these object storage guidelines, you can ensure that your data is properly prepared and accessible for Oracle's Generative AI agents, leading to more effective and efficient AI-driven interactions.\n\nWe just discussed object storage guidelines. Let's now discuss Oracle Database guidelines with respect to the Generative AI agents. Generative AI agents does not manage the database, so you must set up your existing database so Generative AI agents can connect to it.\n\nYou need to create an Oracle Database 23ai table as seen here with the fields such as DOCID, body, and vector. There are optional fields as well, such as CHUNKID, URL, title, and page numbers. Again here, you have the body, which are the chunks of the data, and the text vector, which is the vector generated from the body using an embedding model.\n\nNext, you will need to set up a database function that can return vector search results from each query. A function is a subprogram that can take parameters and returns a value. For the required input, you have parameters such as p_query and top_k. So you can see here the name of the function is retrieval_func_ai. And the two parameters which we pass in this function are p_query and top_k.\n\nThere are some additional requirements too. You must ensure that the embedding model used for the function's query field matches the embedding model that transformed the database table's body content into vector embeddings. This means the embedding model used in the query, which is Cohere embed multilingual v3 must match the embedding model used to generate the text_vec column in the database which we just saw.\n\nThe functions return field must align with the table's required field, which were DOCID, body, and score. If the function's return field names differ from the table field names, you can use aliases within the function. For example, here you have used score as an alias for this calculation.\n\nSo let's see what's happening in this code block. The query accesses a table, which contains vector embeddings. This table also includes the columns such as DOCID, body, and text_vector. The body is the original text content of the document, and text_vec is nothing but the pre-computed vector embeddings of the document content. It then calculates vector distance using cosine similarity or Euclidean distance.\n\nAnd this vector distance is the distance between the query vector and the document embeddings, which is text vector. The query then retrieves the top_k rows sorted by the similarity score in descending order. This ensures the most relevant results are returned to the user. So now, this function returns a SYS_REFCURSOR with the following fields and the fields where DOCID, body, and score. And you can see it returned v_results here and which is used as SYS_REFCURSOR here.\n\nNow, since you are familiar with the guidelines, let's quickly look at the different concepts which we saw earlier and try to understand the overall workflow of creating an agent. So you start with the knowledge base. So this is a knowledge base using object storage as data store. You can see here different objects in the buckets defined as data source for this knowledge base.\n\nSo once you have provided the name, compartment, and other necessary information, you choose the data store type. You can enable hybrid search, which is, again, a combination of lexical as well as semantic search. And then you specify your data source. And the data is stored in this particular bucket.\n\nYou can see there are two objects here. One is text file, another is PDF file. You will click on Create and then go back. You can again either choose to start the ingestion job right away or you can manually create it later. So this is the first step, which is creating a knowledge base.",
  "source_file" : "Section-Chatbot using Gen AI Services.txt",
  "start_line" : 0,
  "end_line" : 0
}, {
  "chunk_id" : "3",
  "title" : "Chunk 3",
  "text" : "Moving on, you can also create a knowledge base for Oracle 23ai. So you again have to provide name, compartment, and other necessary information. In the data store type, you can choose Oracle AI vector search. Again, you set up the database tool connection. List that connection and you provide the vector search function, which we just saw earlier. And then click on Create. And this is how you create a knowledge base for Oracle 23ai.\n\nMoving on, the next step is to create an agent. Again, you will provide some necessary information, then welcome message and instructions for RAG generation if any. Then you will choose one of the knowledge base created earlier. So you can either choose the Oracle 23ai or you can choose the object storage knowledge base.\n\nOnce the agent is created, you can create an endpoint, which is a specific access point that enables the agent to communicate with external systems or different services. Again, you can see different fields and parameters. We discussed session moderation, trace and citation already, so you can choose to select those and apply or not. Then you will click on Create.\n\nMoving on, the next step is the chat. So here, you finally chat with the agent using the agent endpoint, which you just created. And here, you can see the citations and trace. Again, citations are the groundedness or where your information is getting retrieved from. And traces is just maintaining the query as well as the responses.\n\nSo we will further see all of these steps individually in the upcoming lessons. So in case if you are not clear about something, no need to worry. We have two demos, one on object storage knowledge base and other one is on Oracle Database 23ai of knowledge base.\n\nFinally, the one last thing to keep in mind is default resource limits. So you can see different resources listed out here. And you can see their respective default limits here. Keep in mind, you can always raise a request to change.\n\nSo this concludes our topic. So we saw the overview and architecture of OCI Generative AI Agents. We discussed about different agents concepts. We also discussed about object storage and Oracle Database guidelines.\n\n==============================================================================================================================\nChatbot demo using Object Store\n\nHello. And welcome to this demo on generative AI agent. In this demo, we will create a generative AI agent based on object storage data store. So once you are logged in into your OCI account via cloud.oracle.com, you can see, I have chosen Frankfurt region, as the service is available in specific regions. You can check the documentation to learn about the regions where this service is available using docs.oracle.com.\n\nSo first of all, let's click on the Navigation menu, go to Analytics and AI, and then click on Generative Agents under AI Services. It will get you to the Generative AI Agents overview page.\n\nSince we are familiar with the concepts around this topic, let's go through what the process looks like. So usually, it revolves around three steps, which you can see here. The first one is creating a knowledge base. Second one is creating an agent. And third and final one is testing and then chatting with the agent.\n\nSo we will start with creating a knowledge base. So let's click on the knowledge bases from here. You can see two of the knowledge bases created earlier. And they are listed over here. Let's click on Create Knowledge Base.\n\nA knowledge base is the base for all the data source that an agent can use to retrieve the data for its chat answers. So here, we will enter a name first. So for this demo, I will enter demo-kb, which represents knowledge base. Once you have provided a name, you can then select a compartment where you have defined appropriate policies to use this particular service.\n\nYou can also provide a description, although which is optional here. I will leave this as blank. For this demo, we will use object storage as the data store type. So the other two are OCI OpenSearch and Oracle AI Vector Search. For this one, I'm choosing Object Storage.\n\nLet's enable hybrid search, which is a combination of lexical and semantic search. Lexical search basically finds matches based on exact words, characters, or phrases, and is based on keyword-based match. Semantic search finds matches based on meaning and intent, and typically uses vector search.\n\nHybrid approach combines these two. Many modern applications, such as this agent, combines both approaches using RAG, which is retrieval augmented generation, where lexical search retrieves initial candidates and semantic search refines the result for relevance.\n\nIf you do not select this option, you get lexical search only. Now, we need to define our data source. You can have only one data source per knowledge base by default. A data source points to the source of the data. After you add a data source to a knowledge base, you must ingest the data sources data so agents using the knowledge base can reach that data.\n\nIn generative AI agent service, by data source, we mean the service managed OCI Object Storage files, where you can have up to 1,000 text and PDF files of 100 MB each. So let's click on specified data source, which will open a box here.\n\nFor the name, we will, again, type demo and then data source for object storage. Again, you can write a description. For this demo, I will just leave this as it is.\n\nAnother thing is, you can choose to enable multimodal parsing. So you can select this option to parse and include information from charts and graphs in the documents. Then for the data bucket, I can select a bucket of my own choice. For this demo, I will use Gen AI agents, which is a bucket, which I had defined earlier. So now, I will just show you the bucket.\n\nSo this is how the bucket looks like. Again, this bucket is defined in the same compartment. So Gen AI Agents, let's click on this bucket. As this is a professional level course, I expect and assume that you all know how to create a bucket and upload objects to it.\n\nSo for this demo, we will particularly depend upon these two files. The first one is faq.txt. And the other one is oci-ai-foundations.pdf. The first file is a collection of frequently asked questions related to OCI. And the second file is a transcript from our OCI AI foundations course.",
  "source_file" : "Section-Chatbot using Gen AI Services.txt",
  "start_line" : 0,
  "end_line" : 0
}, {
  "chunk_id" : "4",
  "title" : "Chunk 4",
  "text" : "Also keep in mind, only PDF and text files are supported at this point. We have also seen object storage guidelines in the previous lessons.\n\nOK. So let's go back to generative AI agents. So I have selected here Gen AI agents. And then I will select these two files to create our knowledge base using these data source.\n\nThen I will click on Create. So after I have specified the data source, I will select this checkbox to start the ingestion job for this data source and add the data to this knowledge base. After a data ingestion job runs for an object storage data source, you can also review the status logs to confirm that all updated files were successfully ingested.\n\nIf the ingestion job fails, for example, because a file was too large, you can then address the issue and restart the job. Also, when you restart a previously run ingestion job, the pipeline detects files that were successfully ingested earlier and skips them. The pipeline will ingest only files that failed previously and has since been updated. For example, you have 20 files to ingest. And the initial job run results in two failed files.\n\nWhen you restart the job, the pipeline recognizes that 18 files have already been successfully ingested and ignores them. It only ingests two files that failed earlier and have since been updated. Now, let's click on Create.\n\nSo when you run an ingestion job, the data source takes a while to create. Once done, as I just told, make sure to check ingestion log by going to the knowledge base and then clicking on Data Source and then on ingestion job. Once this demo-kb, Knowledge Base, is in active state, as I told earlier, you can click on this.\n\nAnd then on the data source, from there, you can go to the ingestion jobs, click on the jobs, and then check the status logs. You can check and confirm that two files were ingested and processed. Those two files were faq.txt and oci-ai-foundations.pdf.\n\nIf you'll go back, you can also see, we have an option to create ingestion job at a later point of time, if not done at the time of creating a knowledge base. Ingestion jobs add files from object storage with the specified prefix to the data source. Also, new ingestion jobs are required whenever files are added or removed from the object storage bucket.\n\nYou can also cancel an ongoing ingestion job. So under Data Ingestion, you can click on the Actions menu. And for the ingestion job that you want to cancel, and then click Cancel. Here, you can see the lifecycle status, Succeeded. So you can't cancel this. You can cancel the ingestion job only, which are in progress or waiting states.\n\nSo few other things to keep in mind while dealing with the knowledge base. As I said earlier, you can only have one data source per knowledge base. You can update a data source with new data instead of deleting and adding a new one. If you decide to delete a data source, we recommend that you review the data sources content first.\n\nYou can only delete knowledge bases that are not used by agents. Before you delete a knowledge base, you must delete the data sources in that knowledge base and then delete the agents using that data source. The Delete action permanently deletes the knowledge base, and this action can't be undone.\n\nYou can always delete data sources that are used by agents. While the agent continues to run, it no longer answers questions related to the sources that you deleted. The Delete action permanently deletes the data source, and again, this action can't be undone.\n\nSo let's move on to creating an agent. Once the agent is created, and in an Active state, you can click on the agent, and then click on endpoints from the Resources section. Since we have asked the service to create an endpoint, you can see that it has created one for us. If you click on this, you will see also that the trace, citation, and session options are enabled by default, but it hasn't enabled the content moderation on both input and output. These are false.\n\nLet's go back to this endpoints option. Now, if you haven't provided that option to create automatically create an endpoint by default, you can always come here and click on Create Endpoint. You can provide a name.\n\nNow, there is an option to enable session. Enable session keeps the context of the chat session. Another thing to keep in mind, if you enable session, you can specify the idle timeout period in seconds. The default timeout is 3,600 seconds, as you can see here. This is one hour.\n\nThis means that after the lack of activity between the user and agent for one hour, the session automatically ends. And the following conversations do not retain the context of the previous conversation. You can, again, set it as low as one hour and as high as seven days.\n\nFor content moderation, you can select whether the content moderation is applied only on input or output, or both. Here, you can see, both the check marks are there, allowing for both input and output.\n\nYou can select this particular box to enable trace. So it basically tracks and display the conversation history, including both the original prompt and the generated response during the chat conversation. If you don't enable this feature now, you can, again, always add it later by editing the endpoint.\n\nSimilarly, for citations, which display the details about the source of information for each of the chat response, you can, again, edit this option and add it later by editing the endpoint. If you haven't, enable this feature at the time of creation of this endpoint. And then you will click on the Create option. So this should create an endpoint for you if you haven't automatically done during the agent creation stage. I'll click on Cancel here.\n\nNow, I can show you, if you click on this endpoint and then click on this Edit option, as told earlier, you can always edit these, the content moderation, trace, citation. Also, the timeout, what you want to enter.\n\nKeep in mind, there is a difference in enabling the session details, and just changing the timeout period. So if you haven't enabled this session details, you won't even be able to change this timeout period. Anyway, I will check mark these two options. And I will save the changes.",
  "source_file" : "Section-Chatbot using Gen AI Services.txt",
  "start_line" : 0,
  "end_line" : 0
}, {
  "chunk_id" : "5",
  "title" : "Chunk 5",
  "text" : "This will now update this particular endpoint. Once this endpoint is updated, it will, again, be in Active state. You can always launch a chat directly from here by clicking on launch chat on agents page or you can go back. And under Generative AI Agents, click on Chat. We will select an agent to chat with. In our case, demo-agent.\n\nAnd then we will select an endpoint associated with this particular agent. Since we created only one, we will select this endpoint. Now, if you remember from earlier, we had provided this welcome message for this agent.\n\nHi user, I am an AI Assistant. I can help you with answering questions and providing information based on AI Foundations course and Oracle FAQs. How can I help you?\n\nLet's ask a few questions. So let's ask, please tell me about Oracle free tier. Now, we can see a response. Indeed, this is a detailed response.\n\nAlso, we can view the citations and traces. As I told, the citations are nothing but the source, where this answer was taken from. So for example, it has the title, again, object storage path, the document ID, and the source text. You can see multiple sources here.\n\nSimilarly, for traces, you can see the question, the source is retrieved, and the generated text here. Let's ask our next question on the another document. So I'm going to ask, how many modules are there in Oracle AI foundations course? And submit it.\n\nOK. So it says, Oracle Foundations course is split into six modules. Again, you can see the citations and traces. Let's ask another question, who are the instructors for this course?\n\nSo you can see the name of the instructors over here. Again, you can view the citations and related trace. Another thing to note is, again, this is a session-based chat and has the memory. So in the next question, I haven't explicitly specified which course, but the chat understand, this agent understands that I'm asking a question related to the earlier asked question, which was Oracle AI foundations course.\n\nSo this finally concludes our demo, where you created a knowledge base using an object storage as a data source. You then created an agent using this knowledge base. And then you successfully chat with this agent using the agent endpoint.\n==============================================================================================================================\nChatbot using Object Store\n\nHello. And welcome to this demo on generative AI agent. In this demo, we will create a generative AI agent based on object storage data store. So once you are logged in into your OCI account via cloud.oracle.com, you can see, I have chosen Frankfurt region, as the service is available in specific regions. You can check the documentation to learn about the regions where this service is available using docs.oracle.com.\n\nSo first of all, let's click on the Navigation menu, go to Analytics and AI, and then click on Generative Agents under AI Services. It will get you to the Generative AI Agents overview page.\n\nSince we are familiar with the concepts around this topic, let's go through what the process looks like. So usually, it revolves around three steps, which you can see here. The first one is creating a knowledge base. Second one is creating an agent. And third and final one is testing and then chatting with the agent.\n\nSo we will start with creating a knowledge base. So let's click on the knowledge bases from here. You can see two of the knowledge bases created earlier. And they are listed over here. Let's click on Create Knowledge Base.\n\nA knowledge base is the base for all the data source that an agent can use to retrieve the data for its chat answers. So here, we will enter a name first. So for this demo, I will enter demo-kb, which represents knowledge base. Once you have provided a name, you can then select a compartment where you have defined appropriate policies to use this particular service.\n\nYou can also provide a description, although which is optional here. I will leave this as blank. For this demo, we will use object storage as the data store type. So the other two are OCI OpenSearch and Oracle AI Vector Search. For this one, I'm choosing Object Storage.\n\nLet's enable hybrid search, which is a combination of lexical and semantic search. Lexical search basically finds matches based on exact words, characters, or phrases, and is based on keyword-based match. Semantic search finds matches based on meaning and intent, and typically uses vector search.\n\nHybrid approach combines these two. Many modern applications, such as this agent, combines both approaches using RAG, which is retrieval augmented generation, where lexical search retrieves initial candidates and semantic search refines the result for relevance.\n\nIf you do not select this option, you get lexical search only. Now, we need to define our data source. You can have only one data source per knowledge base by default. A data source points to the source of the data. After you add a data source to a knowledge base, you must ingest the data sources data so agents using the knowledge base can reach that data.\n\nIn generative AI agent service, by data source, we mean the service managed OCI Object Storage files, where you can have up to 1,000 text and PDF files of 100 MB each. So let's click on specified data source, which will open a box here.\n\nFor the name, we will, again, type demo and then data source for object storage. Again, you can write a description. For this demo, I will just leave this as it is.\n\nAnother thing is, you can choose to enable multimodal parsing. So you can select this option to parse and include information from charts and graphs in the documents. Then for the data bucket, I can select a bucket of my own choice. For this demo, I will use Gen AI agents, which is a bucket, which I had defined earlier. So now, I will just show you the bucket.\n\nSo this is how the bucket looks like. Again, this bucket is defined in the same compartment. So Gen AI Agents, let's click on this bucket. As this is a professional level course, I expect and assume that you all know how to create a bucket and upload objects to it.\n\nSo for this demo, we will particularly depend upon these two files. The first one is faq.txt. And the other one is oci-ai-foundations.pdf. The first file is a collection of frequently asked questions related to OCI. And the second file is a transcript from our OCI AI foundations course.",
  "source_file" : "Section-Chatbot using Gen AI Services.txt",
  "start_line" : 0,
  "end_line" : 0
}, {
  "chunk_id" : "6",
  "title" : "Chunk 6",
  "text" : "Also keep in mind, only PDF and text files are supported at this point. We have also seen object storage guidelines in the previous lessons.\n\nOK. So let's go back to generative AI agents. So I have selected here Gen AI agents. And then I will select these two files to create our knowledge base using these data source.\n\nThen I will click on Create. So after I have specified the data source, I will select this checkbox to start the ingestion job for this data source and add the data to this knowledge base. After a data ingestion job runs for an object storage data source, you can also review the status logs to confirm that all updated files were successfully ingested.\n\nIf the ingestion job fails, for example, because a file was too large, you can then address the issue and restart the job. Also, when you restart a previously run ingestion job, the pipeline detects files that were successfully ingested earlier and skips them. The pipeline will ingest only files that failed previously and has since been updated. For example, you have 20 files to ingest. And the initial job run results in two failed files.\n\nWhen you restart the job, the pipeline recognizes that 18 files have already been successfully ingested and ignores them. It only ingests two files that failed earlier and have since been updated. Now, let's click on Create.\n\nSo when you run an ingestion job, the data source takes a while to create. Once done, as I just told, make sure to check ingestion log by going to the knowledge base and then clicking on Data Source and then on ingestion job. Once this demo-kb, Knowledge Base, is in active state, as I told earlier, you can click on this.\n\nAnd then on the data source, from there, you can go to the ingestion jobs, click on the jobs, and then check the status logs. You can check and confirm that two files were ingested and processed. Those two files were faq.txt and oci-ai-foundations.pdf.\n\nIf you'll go back, you can also see, we have an option to create ingestion job at a later point of time, if not done at the time of creating a knowledge base. Ingestion jobs add files from object storage with the specified prefix to the data source. Also, new ingestion jobs are required whenever files are added or removed from the object storage bucket.\n\nYou can also cancel an ongoing ingestion job. So under Data Ingestion, you can click on the Actions menu. And for the ingestion job that you want to cancel, and then click Cancel. Here, you can see the lifecycle status, Succeeded. So you can't cancel this. You can cancel the ingestion job only, which are in progress or waiting states.\n\nSo few other things to keep in mind while dealing with the knowledge base. As I said earlier, you can only have one data source per knowledge base. You can update a data source with new data instead of deleting and adding a new one. If you decide to delete a data source, we recommend that you review the data sources content first.\n\nYou can only delete knowledge bases that are not used by agents. Before you delete a knowledge base, you must delete the data sources in that knowledge base and then delete the agents using that data source. The Delete action permanently deletes the knowledge base, and this action can't be undone.\n\nYou can always delete data sources that are used by agents. While the agent continues to run, it no longer answers questions related to the sources that you deleted. The Delete action permanently deletes the data source, and again, this action can't be undone.\n\nSo let's move on to creating an agent. Once the agent is created, and in an Active state, you can click on the agent, and then click on endpoints from the Resources section. Since we have asked the service to create an endpoint, you can see that it has created one for us. If you click on this, you will see also that the trace, citation, and session options are enabled by default, but it hasn't enabled the content moderation on both input and output. These are false.\n\nLet's go back to this endpoints option. Now, if you haven't provided that option to create automatically create an endpoint by default, you can always come here and click on Create Endpoint. You can provide a name.\n\nNow, there is an option to enable session. Enable session keeps the context of the chat session. Another thing to keep in mind, if you enable session, you can specify the idle timeout period in seconds. The default timeout is 3,600 seconds, as you can see here. This is one hour.\n\nThis means that after the lack of activity between the user and agent for one hour, the session automatically ends. And the following conversations do not retain the context of the previous conversation. You can, again, set it as low as one hour and as high as seven days.\n\nFor content moderation, you can select whether the content moderation is applied only on input or output, or both. Here, you can see, both the check marks are there, allowing for both input and output.\n\nYou can select this particular box to enable trace. So it basically tracks and display the conversation history, including both the original prompt and the generated response during the chat conversation. If you don't enable this feature now, you can, again, always add it later by editing the endpoint.\n\nSimilarly, for citations, which display the details about the source of information for each of the chat response, you can, again, edit this option and add it later by editing the endpoint. If you haven't, enable this feature at the time of creation of this endpoint. And then you will click on the Create option. So this should create an endpoint for you if you haven't automatically done during the agent creation stage. I'll click on Cancel here.\n\nNow, I can show you, if you click on this endpoint and then click on this Edit option, as told earlier, you can always edit these, the content moderation, trace, citation. Also, the timeout, what you want to enter.\n\nKeep in mind, there is a difference in enabling the session details, and just changing the timeout period. So if you haven't enabled this session details, you won't even be able to change this timeout period. Anyway, I will check mark these two options. And I will save the changes.",
  "source_file" : "Section-Chatbot using Gen AI Services.txt",
  "start_line" : 0,
  "end_line" : 0
}, {
  "chunk_id" : "7",
  "title" : "Chunk 7",
  "text" : "This will now update this particular endpoint. Once this endpoint is updated, it will, again, be in Active state. You can always launch a chat directly from here by clicking on launch chat on agents page or you can go back. And under Generative AI Agents, click on Chat. We will select an agent to chat with. In our case, demo-agent.\n\nAnd then we will select an endpoint associated with this particular agent. Since we created only one, we will select this endpoint. Now, if you remember from earlier, we had provided this welcome message for this agent.\n\nHi user, I am an AI Assistant. I can help you with answering questions and providing information based on AI Foundations course and Oracle FAQs. How can I help you?\n\nLet's ask a few questions. So let's ask, please tell me about Oracle free tier. Now, we can see a response. Indeed, this is a detailed response.\n\nAlso, we can view the citations and traces. As I told, the citations are nothing but the source, where this answer was taken from. So for example, it has the title, again, object storage path, the document ID, and the source text. You can see multiple sources here.\n\nSimilarly, for traces, you can see the question, the source is retrieved, and the generated text here. Let's ask our next question on the another document. So I'm going to ask, how many modules are there in Oracle AI foundations course? And submit it.\n\nOK. So it says, Oracle Foundations course is split into six modules. Again, you can see the citations and traces. Let's ask another question, who are the instructors for this course?\n\nSo you can see the name of the instructors over here. Again, you can view the citations and related trace. Another thing to note is, again, this is a session-based chat and has the memory. So in the next question, I haven't explicitly specified which course, but the chat understand, this agent understands that I'm asking a question related to the earlier asked question, which was Oracle AI foundations course.\n\nSo this finally concludes our demo, where you created a knowledge base using an object storage as a data source. You then created an agent using this knowledge base. And then you successfully chat with this agent using the agent endpoint.\n\n========================================================================================================================\nChatbot demo using 23ai\n\nWelcome to this second demo on generative AI agent. In this demo, we will create a generative AI agent based on Oracle Database 23ai data store. Keep in mind, I have already set up necessary policies and permissions. I have also created and configured a VCN and updated the security rules as well. And lastly, I have created a vault to store database secrets.\n\nI'm not going to include these steps in this demo, as this course is a professional level course, and we assume that you have hands-on experience with OCI. But for more information on this setup processes, you can refer to our documentation on docs.oracle.com. You can go here and search for agents, and then you can click on Generative AI agents. Once here, you can read the Getting Access section and then also Oracle Database Guidelines section for further info.\n\nLet's go back and we will start with creating a database. So once you all are logged in into your OCI account via cloud.oracle.com, you can click again on the Navigation menu, go to Oracle Database, and then click on Autonomous Database. Here, click on Create Autonomous Database, and then provide information for compartment, display name, and database name.\n\nSo I'll provide demoagent as my display as well as database name. For workload type, I'm going to choose Data Warehouse, and for deployment type, I will keep it as Serverless. Now, for the database version, you have to choose 23ai and let the other things remain as default. Now you can give a password of your preference.\n\nLook here.\n\nSo once you have given your password, make sure to select the network access and private endpoint access only. Now I will select the VCN, which I had already created, and then subnet. Also, make sure you do not click on this Require mutual TLS authentication.\n\nFinally, provide a valid email ID and click on Create Autonomous Database. Once the database is created, you will receive an email. Regardless, check this page for your database and make sure that you see your database in available state.\n\nLet's click on this database. Go to Database connection and choose any one of the connection strings. Click on Copy, then close. Make sure you copy this on a Word document. Then under Network section, make sure you choose your private endpoint IP and copy it on the document.\n\nNow we will create a database tool connection. So from Navigation menu, go to Developer Services, and under Database Tools, click on Connections. Once here, click on Create connection. You need to provide a name and compartment information. You also need to choose Oracle Autonomous Database as database cloud service and then provide username as admin.\n\nSo let's do all of those steps one by one. So I'm going to use the same name, demoagent. For database cloud service, Oracle Autonomous Database. I will choose just a newly created database. And for username, I'm going to put admin.\n\nClick on Create password secret. Here you, again, need to provide the name, vault, and key, which you would have created earlier. Also, in the user password, provide the same password which you created and used at the time of Autonomous Database creation in the previous task.\n\nSo I'll put the same name, demoagent. For vault, I will choose earlier created vault and encryption key. For user password, I will use the same password, which I used during the Autonomous Database creation, and then click on Create.\n\nOnce created, you can use the newly created password secret here. So click on demoagent, in my case. We will also modify our connection string, which we had copied earlier. So for retry count 20, we'll make it 3, and we will replace the host with the correct IP address.\n\nLet's copy this string.\n\nIn the private endpoint, you can select the private endpoint which you would have created earlier. For the wallet, in the SSL details, let it be None, and then click on Create. Once the database tool connection is created, click on Validate.\n\nIf it's successfully connected to your database, it should show a validation connection, Done. Click on Close. Next, we have to load the vector data in the Autonomous Database. So on this page, you need to click on SQL worksheet.",
  "source_file" : "Section-Chatbot using Gen AI Services.txt",
  "start_line" : 0,
  "end_line" : 0
}, {
  "chunk_id" : "8",
  "title" : "Chunk 8",
  "text" : "We will run these code blocks one by one. This first code block is for access control list to let user go out everywhere. This is required for Autonomous Database user to access bucket, public link, and GenAI embedding model. I will select this one and run it.\n\nIn this next code block, you will create the credentials to access OCI Generative AI Service so you can find these credentials such as user_ocid, tenancy_ocid, private_key, fingerprint in your profile section. This first block is the Database Management System Cloud credential, and the second block is the credentials for your generative AI service. Let's run this one by one.\n\nWe will run this code block to test and this should return vector embedding for Hello.\n\nWe can see we are using cohere.embed-multilingual-v3.0 for the embedding model. Here, the embedding has been created for the word Hello. And that means we can use generative AI embedding model to create embeddings using the credentials which we provided earlier.\n\nNow we will go back to these buckets in the object storage. You can see here that I had created this bucket, GenAI-Agents, and uploaded a text file called faq.txt. We had also used this particular file in the previous demo. We will now create a preauthenticated request link to access this text file.\n\nSo click on Create Preauthenticated Request object. And then I'll just change the dates and then create preauthenticated request. I'll copy this link, go back to the SQL worksheet. Now this code block will divide the blob into chunks using this utl_to_chunks function.\n\nAnd at the end, it will create a table, ai_extracted_data. And we will have some particular columns as our fields-- chunk_id, chunk_offset, chunk_length, and chunk_data. The link which we just copied we will paste it here.\n\nAnd now we will run this code block.\n\nSo it says the TABLE_AI_EXTRACTED_DATA has been created. Let's check this table.\n\nSo we can see chunk_id, chunk_offset, chunk_length, and chunk_data. Let's run this code block to create the vector table.\n\nSo this AI_EXTRACTED_DATA_VECTOR table has been created. Now we will insert the data into this table. Again, see here that for the embedding model we have used cohere.embed-multilingual-v3.\n\nSo this vector table has been created.\n\nYou would have remembered this function from our first lesson in this module where we created this retrieval_func_ai function. Let's run this code block.\n\nYou can see that the function retrieval_func_ai has been compiled. You can also run and check the function with this code block.\n\nYou can see I'm also running a query to check that function-- Tell me about Oracle Free Tier Account, and only top 10 results will be included. So if you will expand this, you can see there are total of 10 results here.\n\nSince all of these steps are completed, you can always refresh this and open these tables to see what kind of data is stored there. For example, if I open this AI_EXTRACTED_DATA_VECTOR table, you can see here the data.\n\nSo whatever data I had in my faq.txt file, those has been chunked and vectorized. And you can see the body or the content and the corresponding vector embedding. So we now have a vector database. So we can close this and move back to the agents.\n\nSo again, go to Analytics and AI, and then Generative AI Agents. We will now follow the same steps or similar steps what we did for the object storage. So click on the Knowledge Bases, then create knowledge base, provide a name, demo, and then knowledge base.\n\nThis time we will select Oracle AI Vector Search as our data store type. For database tool connection, we will select demoagent, which we had created. We can again test our connection, which is successful. For the vector search function, we had created a RETRIEVAL_FUNCTION_AI. So we will select that, and then click on Create.\n\nSo this will initiate our knowledge base creation. It should take some time. Knowledge base has been created as an active lifecycle state. So we'll click on agents and then click on Create agent and put a name here. So demo-agent.\n\nAnd then for the welcome message, if I leave it blank, this message will be shown. In our case, I can put something like, Hi user, I am a chatbot for Oracle FAQs. Please ask me related questions.\n\nI'm going to leave these instructions for RAG as it is. And then I will select the knowledge base which we had created earlier. And here, we will check mark this for automatically creating an endpoint for this agent, and then click on Create.\n\nSo you will see License Agreement and Acceptable Use Policy. Accept that and click on Submit. And this will successfully initiate the agent creation as well as agent endpoint creation. This agent is now active. So let's go to the chat.\n\nSelect agent created in the previous task from the dropdown, which is demo-agent. Also, select the endpoint associated with that agent. Now you can see the message which I had put earlier-- Hi user, I am a chatbot for Oracle FAQs. Please ask me related questions. I will type a question, Tell me about Oracle Free Tier.\n\nYou can see we have a response now with citations and traces. So traces has the input as well as the output, and the citations quotes different documents where this answer was found.\n\nSo this concludes the demo. We created an Autonomous Database and a database connection tool. We then load vector data using SQL and created a vector table. Then we created a knowledge base, an agent, an endpoint, and did chat with the created agent.\n\nI didn't delve into the details of the SQL since the demo is more about the OCI Generative AI agent services itself, and how you deal with the data is your own choice, but I will definitely recommend our Oracle Database 23ai course if you are interested any further. Thanks for joining.",
  "source_file" : "Section-Chatbot using Gen AI Services.txt",
  "start_line" : 0,
  "end_line" : 0
} ]