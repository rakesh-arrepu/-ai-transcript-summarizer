```markdown
# Practice Questions on Large Language Models

## Multiple Choice Questions
1. What do LLMs compute?
   - A) Text distributions
   - B) Image distributions
   - C) Sound distributions
   - D) None of the above
   - **Answer**: A*

2. Which architecture is designed for text generation?
   - A) Encoder
   - B) Decoder
   - C) Both
   - D) None
   - **Answer**: B*

3. What is 'prompt engineering'?
   - A) Training the model
   - B) Refining model inputs
   - C) Generating text
   - D) None of the above
   - **Answer**: B*

4. What does 'k-shot prompting' entail?
   - A) Providing no examples
   - B) Providing multiple examples
   - C) Providing one example
   - D) Providing random inputs
   - **Answer**: B*

5. What is a primary method to mitigate hallucinations in LLMs?
   - A) Fine-tuning
   - B) RAG
   - C) Greedy decoding
   - D) Soft prompting
   - **Answer**: B*

6. Which of the following is NOT a decoding strategy?
   - A) Beam Search
   - B) Greedy Decoding
   - C) Temperature Adjustment
   - D) Chain-of-Thought
   - **Answer**: D*

## Short Answer Questions
1. Define `hallucination` in the context of LLMs.
   - **Answer**: Hallucination refers to text generated by LLMs that is not grounded in training data, often resulting in factually incorrect but fluent-sounding content.

2. What is the purpose of RAG systems?
   - **Answer**: RAG systems provide external documents as context to LLMs to reduce hallucination and improve the accuracy of generated responses.

3. Explain the difference between fine-tuning and parameter-efficient methods like LoRA.
   - **Answer**: Fine-tuning adjusts all model parameters for a specific task, while parameter-efficient methods like LoRA modify only a subset of parameters, reducing computational costs.

4. Describe `soft prompting`.
   - **Answer**: Soft prompting is a training method that adds learnable parameters to prompts, which are fine-tuned to cue specific tasks during model training.

5. What is a key challenge with prompt engineering?
   - **Answer**: The key challenge is that it can be unintuitive and requires iterative refinement to achieve desired outputs, making the process complex.

6. What are language agents in the context of LLMs?
   - **Answer**: Language agents are models designed to operate in environments and take sequential actions to accomplish specific goals based on their interactions.

## Long Form Questions
1. Discuss the impact of temperature in decoding strategies and its influence on text generation.
   - **Marking Rubric**:
     - Definition of temperature (1 point)
     - Explanation of its role in controlling output creativity vs conservativism (2 points)
     - Examples of how different temperatures affect output (2 points)

2. Analyze the limitations of current code models and potential future advancements in LLM technology.
   - **Marking Rubric**:
     - Description of current limitations, particularly in bug fixing (2 points)
     - Discussion on multi-modal capabilities and their importance (2 points)
     - Speculation on future advancements and applications of LLMs (2 points)

## Answer Key
### Multiple Choice
1. A
2. B
3. B
4. B
5. B
6. D

### Short Answer
1. Hallucination refers to text generated by LLMs that is not grounded in training data, often resulting in factually incorrect but fluent-sounding content. (1 point)
2. RAG systems provide external documents as context to LLMs to reduce hallucination and improve the accuracy of generated responses. (1 point)
3. Fine-tuning adjusts all model parameters for a specific task, while parameter-efficient methods like LoRA modify only a subset of parameters, reducing computational costs. (2 points)
4. Soft prompting is a training method that adds learnable parameters to prompts, which are fine-tuned to cue specific tasks during model training. (1 point)
5. The key challenge is that it can be unintuitive and requires iterative refinement to achieve desired outputs, making the process complex. (1 point)
6. Language agents are models designed to operate in environments and take sequential actions to accomplish specific goals based on their interactions. (1 point)

### Long Form
- **Question 1**: (Graded based on rubric)
- **Question 2**: (Graded based on rubric)
```