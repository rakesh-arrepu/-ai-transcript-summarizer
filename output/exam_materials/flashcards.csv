```csv
"Front","Back"
"Define LLMs","LLMs are probabilistic models that compute distributions over vocabulary words."
"What does 'large' refer to in LLMs?","'Large' refers to the parameter count, with no standard threshold defined."
"What is the function of an Encoder in LLMs?","An Encoder converts text into vector representations, as seen in models like BERT."
"What is the function of a Decoder in LLMs?","A Decoder generates text sequences one token at a time, exemplified by models like GPT-4."
"What is an Encoder-Decoder architecture?","An Encoder-Decoder combines both encoders and decoders for tasks like translation."
"Give an example of an Encoder model.","BERT is an example of an Encoder model used for tasks like sentiment analysis."
"Give an example of a Decoder model.","GPT-4 is an example of a Decoder model used for generating creative writing."
"What is prompting in LLMs?","Prompting changes the input text to influence the model's output distributions."
"What is prompt engineering?","Prompt engineering is the iterative refinement of model inputs to achieve desired outputs."
"Define zero-shot learning.","Zero-shot learning involves using a model to perform tasks without providing any examples."
"Define k-shot learning.","K-shot learning includes providing k examples to guide the model's behavior."
"What is chain-of-thought prompting?","Chain-of-thought prompting breaks complex problems into smaller, manageable steps."
"What is least-to-most prompting?","Least-to-most prompting solves simpler tasks first to build toward solutions."
"What is concept-based prompting?","Concept-based prompting utilizes first principles for scientific problem-solving."
"What is prompt injection?","Prompt injection is manipulating inputs to elicit unintended outputs from the model."
"Explain fine-tuning in LLMs.","Fine-tuning adjusts all parameters of a model for a specific task to improve performance."
"What are parameter-efficient methods?","Parameter-efficient methods, like LoRA, modify only certain parameters to reduce computational demand."
"What is soft prompting?","Soft prompting adds trainable parameters to cues, allowing for specific task tuning."
"What is greedy decoding?","Greedy decoding selects the highest probability word at each generation step."
"Define nucleus sampling.","Nucleus sampling samples from a defined portion of the probability distribution to generate text."
"What is beam search?","Beam search generates multiple sequences and selects the best one for output."
"What is hallucination in LLMs?","Hallucination refers to the generation of text not grounded in training data, often resulting in inaccuracies."
"What is retrieval-augmented generation (RAG)?","RAG uses external documents to provide context and reduce hallucination in generated responses."
"What is a limitation of current code models?","Current code models can fix bugs only 15% of the time, indicating their limitations."
"What are multi-modal models?","Multi-modal models are capable of handling various data types, including text, images, and audio."
"What are language agents?","Language agents execute sequential actions in decision-making tasks based on context and interactions."
"What do LLMs compute?","LLMs compute word probabilities over a given vocabulary."
"Which architecture generates text?","The Decoder architecture is specifically designed for text generation."
"What is the purpose of prompt engineering?","The purpose of prompt engineering is to refine model inputs for achieving specific desired outputs."
"What does k-shot prompting involve?","K-shot prompting involves providing multiple examples to guide the model's predictions."
"Identify a primary method to mitigate hallucinations.","Retrieval-Augmented Generation (RAG) is a primary method to mitigate hallucinations."
"Which is NOT a decoding strategy?","Chain-of-Thought is not a decoding strategy; it is a prompting technique."
"Define hallucination in LLMs context.","Hallucination is when LLMs generate text that is not factually grounded in their training data."
"What is the role of RAG systems?","RAG systems provide external context to reduce hallucination and improve response accuracy."
"Differentiate fine-tuning and LoRA.","Fine-tuning adjusts all parameters for a task, while LoRA modifies only specific parameters."
"Explain soft prompting.","Soft prompting involves adding trainable parameters to prompts to cue specific tasks during training."
"What is a challenge with prompt engineering?","A key challenge is that prompt engineering can be unintuitive and requires iterative refinement."
"What are language agents?","Language agents are models that perform sequential actions to achieve specific goals based on context."
"Discuss temperature in decoding strategies.","Temperature controls the randomness of predictions in text generation, affecting creativity versus conservatism."
"Analyze limitations of code models.","Current limitations include poor bug fixing, with code models fixing issues only 15% of the time."
"Speculate on future advancements in LLMs.","Future advancements may include improved multi-modal capabilities and more robust handling of diverse tasks."
"Define soft prompting in LLMs.","Soft prompting refers to adding learnable parameters to cues which are fine-tuned for specific tasks."
"What is the impact of temperature on text generation?","It influences the creativity of output, where lower temperatures yield more predictable text and higher temperatures produce more varied results."
"Describe how multi-modal models work.","Multi-modal models can process and generate multiple forms of data, such as combining text, images, and audio inputs."
"What is the main goal of RAG systems?","The main goal of RAG systems is to provide relevant external information to enhance the accuracy of generated responses."
"Identify one challenge of using LLMs for structured tasks.","One challenge is that code models often fail to fix bugs effectively, indicating limitations in their reliability."
"What is the significance of chain-of-thought prompting?","Chain-of-thought prompting aids in breaking down complex problems into simpler steps, enhancing model understanding."
"Explain least-to-most prompting in task management.","Least-to-most prompting prioritizes simpler tasks first, allowing the model to build solutions step-by-step."
"Define concept-based prompting in problem-solving.","Concept-based prompting uses fundamental principles to tackle scientific or complex problems effectively."
```