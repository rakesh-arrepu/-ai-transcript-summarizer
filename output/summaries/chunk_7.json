{
  "chunk_id" : "7",
  "title" : "Decoding Strategies and Hallucination in LLMs",
  "summary" : "This chunk covers non-deterministic decoding strategies in LLMs, particularly focusing on temperature parameter effects on text generation, followed by an introduction to hallucination - when models generate text unsupported by training data or factually incorrect information that appears fluent and believable.",
  "key_points" : [ "Temperature parameter modulates probability distributions in non-deterministic decoding", "Lower temperature produces more typical/conservative outputs; higher temperature enables more creative generation", "Relative word ordering by probability remains unchanged regardless of temperature", "Hallucination is text generated without grounding in training data or input context", "Hallucinations can be subtle and dangerous, especially in unfamiliar domains" ],
  "workflows" : [ {
    "name" : "Random Sampling Decoding",
    "steps" : [ "Generate probability distribution over vocabulary", "Randomly sample word from available choices", "Append selected word to input sequence", "Feed modified input back to LLM", "Repeat until EOS token generated" ],
    "notes" : "Probabilities update based on context from previously selected words"
  }, {
    "name" : "Temperature-Controlled Generation",
    "steps" : [ "Generate initial probability distribution", "Apply temperature parameter to modulate distribution", "Sample from adjusted distribution", "Generate next token based on sampling strategy" ],
    "notes" : "Lower temperature = more peaked distribution; higher temperature = flatter distribution"
  } ],
  "definitions" : [ {
    "term" : "Temperature",
    "definition" : "Parameter that modulates probability distribution over words in non-deterministic decoding; affects creativity vs conservatism of outputs"
  }, {
    "term" : "Hallucination",
    "definition" : "Text generated by a model that is not grounded by training data or input, often factually incorrect but fluent-sounding"
  }, {
    "term" : "Nucleus Sampling",
    "definition" : "Sampling-based decoding method with additional parameters governing what portion of probability distribution can be sampled from"
  }, {
    "term" : "Beam Search",
    "definition" : "Decoding method that generates multiple sequences simultaneously and prunes low-probability sequences to find higher joint probability outputs"
  } ],
  "examples" : [ "Red panda example: 'small red panda' generated through context-aware probability updates", "Driving hallucination: 'In the United States, people drive on the left side' (factually incorrect)", "Subtle hallucination: 'Barack Obama was the first president of the United States' (missing 'Black' adjective)" ],
  "exam_pointers" : [ "Temperature controls creativity: low = conservative, high = creative output", "Hallucinations maintain fluency while being factually incorrect or unsupported", "Three main decoding types: greedy, nucleus sampling, beam search", "Relative probability ordering preserved regardless of temperature setting" ],
  "confidence" : "high"
}