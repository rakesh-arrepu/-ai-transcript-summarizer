# Transcript ‚Üí Exam Notes Pipeline

Convert lecture transcripts into comprehensive, exam-ready study materials automatically. This tool uses AI to chunk, summarize, and consolidate transcripts into master notes, flashcards, practice questions, and quick revision sheets.

## üéØ Features

- **Semantic Text Chunking**: Intelligently split transcripts into manageable chunks preserving topic boundaries
- **AI-Powered Summarization**: Use Claude, GPT, or Gemini API to create structured, high-quality summaries
- **Master Notes Generation**: Consolidate summaries into comprehensive study documents (Markdown)
- **Exam Materials**: Auto-generate:
  - Flashcards (CSV format for Anki/Quizlet)
  - Practice questions (MCQ, short-answer, long-form)
  - Quick revision sheets (1-page summary)
- **Multi-Model Support**: Claude 3.5 Sonnet, GPT-4o, and Gemini 2.5 Pro
- **Cost Optimization**: Save up to 77-95% using Gemini instead of Claude+GPT
- **Quality Tracking**: Confidence levels for each summary item
- **Interactive & CLI Modes**: Use the interactive menu or command-line arguments
- **State Tracking**: Resume interrupted pipeline runs
- **Error Handling**: Automatic retries with exponential backoff for API calls

## üöÄ Quick Start (5 minutes)

### 1. Prerequisites
- **Java 17+** (LTS version recommended)
- **Maven 3.8+**
- **API Keys** (at least one required):
  - [Anthropic Claude API Key](https://console.anthropic.com)
  - [OpenAI API Key](https://platform.openai.com/api-keys)
  - [Google Gemini API Key](https://aistudio.google.com/app/apikey) ‚≠ê **Recommended for cost savings**

### 2. Setup

```bash
# Clone the repository
git clone <repository-url>
cd transcript-to-exam-notes

# Create .env file with your API keys
cp config/.env.example .env

# Edit .env with your keys (at least one model per step required)
# For best quality (default):
# CLAUDE_API_KEY=sk-ant-xxxxx
# OPENAI_API_KEY=sk-xxxxx

# For cost savings (recommended):
# CLAUDE_API_KEY=sk-ant-xxxxx
# GEMINI_API_KEY=AIzaSy... (from https://aistudio.google.com/app/apikey)
# CONSOLIDATOR_MODEL=gemini
```

### 3. Build Project

```bash
# Build with Maven
mvn clean package

# This creates: target/transcript-pipeline.jar
```

### 4. Run Interactive Mode

```bash
java -jar target/transcript-pipeline.jar
```

Follow the menu to:
1. Place `.txt` transcript files in `transcripts/` directory
2. Choose "Run complete pipeline"
3. Let the tool generate all study materials

### 5. Outputs

Generated files appear in `output/`:
```
output/
‚îú‚îÄ‚îÄ chunks/
‚îÇ   ‚îî‚îÄ‚îÄ lesson1_chunks.json          # Chunked transcripts
‚îú‚îÄ‚îÄ summaries/
‚îÇ   ‚îú‚îÄ‚îÄ chunk_1.json
‚îÇ   ‚îú‚îÄ‚îÄ chunk_2.json
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ consolidated/
‚îÇ   ‚îî‚îÄ‚îÄ master_notes.md              # Main study document
‚îî‚îÄ‚îÄ exam_materials/
    ‚îú‚îÄ‚îÄ flashcards.csv               # For Anki/Quizlet
    ‚îú‚îÄ‚îÄ practice_questions.md        # Test yourself
    ‚îî‚îÄ‚îÄ quick_revision.md            # 1-page summary
```

## üìö Workflow

```
Transcripts (*.txt)
        ‚Üì
    [CHUNKING]
        ‚Üì
  Chunks (JSON)
        ‚Üì
  [SUMMARIZATION]
        ‚Üì
 Chunk Summaries (JSON)
        ‚Üì
 [CONSOLIDATION]
        ‚Üì
Master Notes (Markdown)
        ‚Üì
[EXAM MATERIALS]
        ‚Üì
Flashcards / Q&A / Quick Revision
```

## üéÆ Interactive Menu

```
üìã MAIN MENU
1. Run complete pipeline
2. Chunk transcripts only
3. Summarize chunks only
4. Consolidate to master notes
5. Generate exam materials
6. View pipeline status
7. Settings
8. Help
0. Exit
```

Choose options to run full pipeline or individual steps.

## üõ†Ô∏è Technical Stack

| Component | Technology |
|-----------|-----------|
| **Language** | Java 17+ |
| **Build Tool** | Maven 3.8+ |
| **HTTP Client** | OkHttp 4.11 |
| **JSON Processing** | Jackson 2.15 |
| **Logging** | SLF4J 2.0 |
| **CLI** | Apache Commons CLI |
| **Configuration** | .env files + Environment variables |

## üîë API Configuration

### Environment Variables

Create a `.env` file in the project root:

```env
# ============================================================================
# REQUIRED API KEYS (at least one per model type)
# ============================================================================

# Anthropic Claude API Key
# Get from: https://console.anthropic.com/
CLAUDE_API_KEY=sk-ant-xxxxx

# OpenAI API Key
# Get from: https://platform.openai.com/api-keys
OPENAI_API_KEY=sk-xxxxx

# Google Gemini API Key (recommended for cost savings)
# Get from: https://aistudio.google.com/app/apikey
GEMINI_API_KEY=AIzaSy_xxxxxxxxxxxxx

# ============================================================================
# API ENDPOINTS (Optional - for proxies or custom endpoints)
# ============================================================================
CLAUDE_API_BASE=https://api.anthropic.com/v1
OPENAI_API_BASE=https://api.openai.com/v1
GEMINI_API_BASE=https://generativelanguage.googleapis.com/v1beta/openai/

# ============================================================================
# PIPELINE MODEL SELECTION
# ============================================================================
# Choose which model to use for each step (default: claude + gpt)
SUMMARIZER_MODEL=claude      # or gemini
CONSOLIDATOR_MODEL=gpt       # or gemini

# ============================================================================
# PIPELINE CONFIGURATION
# ============================================================================
TRANSCRIPT_DIR=transcripts
OUTPUT_DIR=output
LOGS_DIR=logs

# ============================================================================
# CHUNKING PARAMETERS
# ============================================================================
CHUNK_SIZE=1500              # Estimated tokens per chunk
CHUNK_OVERLAP=200            # Overlap tokens between chunks

# ============================================================================
# API PARAMETERS
# ============================================================================
API_TIMEOUT=60000            # Timeout in milliseconds
MAX_RETRIES=3                # Retry attempts for failed requests
RETRY_BACKOFF=1000           # Initial backoff in milliseconds

# ============================================================================
# MODEL SPECIFICATIONS
# ============================================================================
MODEL_CLAUDE=claude-3-5-sonnet-20241022
MODEL_GPT=gpt-4o
MODEL_GEMINI=gemini-2.5-flash
```

## üí∞ Cost Optimization with Gemini

### Model Combinations & Pricing

| Configuration | Summarizer | Consolidator | Cost/Lecture | Savings | Quality |
|---|---|---|---|---|---|
| **Default (Best Quality)** | Claude | GPT-4o | ~$2.15 | Baseline | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Cost-Optimized ‚≠ê** | Claude | Gemini | ~$0.50 | **77%** | ‚≠ê‚≠ê‚≠ê‚≠ê |
| **Budget Mode** | Gemini | Gemini | ~$0.10 | **95%** | ‚≠ê‚≠ê‚≠ê |

### How to Enable Gemini

**For 77% cost savings (recommended):**
```env
CONSOLIDATOR_MODEL=gemini
GEMINI_API_KEY=AIzaSy_your_key_from_https://aistudio.google.com/app/apikey
```

**For 95% cost savings:**
```env
SUMMARIZER_MODEL=gemini
CONSOLIDATOR_MODEL=gemini
GEMINI_API_KEY=AIzaSy_your_key_from_https://aistudio.google.com/app/apikey
```

### API Reference Links
- **Claude**: [console.anthropic.com](https://console.anthropic.com) | [Documentation](https://docs.anthropic.com)
- **OpenAI**: [platform.openai.com](https://platform.openai.com/api-keys) | [Documentation](https://platform.openai.com/docs)
- **Gemini**: [aistudio.google.com](https://aistudio.google.com/app/apikey) | [Documentation](https://ai.google.dev/docs)

For detailed Gemini integration guide, see [GEMINI_INTEGRATION_GUIDE.md](./GEMINI_INTEGRATION_GUIDE.md)

## üìñ Configuration Defaults

If not specified in `.env`:

| Parameter | Default |
|-----------|---------|
| `TRANSCRIPT_DIR` | `transcripts` |
| `OUTPUT_DIR` | `output` |
| `LOGS_DIR` | `logs` |
| `CHUNK_SIZE` | 1500 tokens |
| `CHUNK_OVERLAP` | 200 tokens |
| `API_TIMEOUT` | 60 seconds |
| `MAX_RETRIES` | 3 attempts |
| `RETRY_BACKOFF` | 1 second |

## üìä Output File Formats

### Master Notes (Markdown)
```markdown
# Master Notes

## Topic 1
- Summary text
- Key points
- Definitions
- Examples

## Topic 2
...
```

### Flashcards (CSV)
```csv
"Front","Back"
"What is photosynthesis?","Process converting light energy to chemical energy"
"Define: Chlorophyll","Green pigment in plants for light absorption"
...
```

### Practice Questions (Markdown)
```markdown
## Multiple Choice
### Q1: Which of the following...
a) Option A
b) Option B
c) Option C
d) Option D

*Answer: b

## Short Answer
### Q6: Explain the process of...
Expected Answer: ...
```

## ‚öôÔ∏è Advanced Configuration

### Custom Chunk Size
To adjust chunk size (in estimated tokens):

```env
CHUNK_SIZE=2000              # Larger chunks
CHUNK_OVERLAP=300            # More overlap
```

### API Retry Strategy
```env
MAX_RETRIES=5                # More retry attempts
RETRY_BACKOFF=2000           # Longer backoff (2s)
```

### Custom API Endpoints
For corporate proxies or alternative providers:

```env
CLAUDE_API_BASE=https://proxy.company.com/anthropic
OPENAI_API_BASE=https://proxy.company.com/openai
```

## üîí Security

### API Key Safety

- **Never commit `.env`** to version control
- `.env` is in `.gitignore` by default
- Use environment variables in production:
  ```bash
  export CLAUDE_API_KEY=sk-ant-xxxxx
  export OPENAI_API_KEY=sk-xxxxx
  java -jar target/transcript-pipeline.jar
  ```

### Best Practices
1. Use a secrets manager in production (Vault, 1Password, AWS Secrets)
2. Rotate API keys regularly
3. Monitor API usage for unusual activity
4. Use separate API keys for dev/prod environments

## üìù Input Format

### Transcript Files
- **Location**: `transcripts/` directory
- **Format**: Plain text (`.txt`)
- **Encoding**: UTF-8
- **Size**: Up to several thousand lines per file
- **Structure**: Any format (headings optional)

Example `lesson1.txt`:
```
# Introduction to Biology

Lecture delivered by Dr. Smith on March 15, 2024

## Cell Structure

Cells are the basic units of life. There are two main types:
- Prokaryotic cells (bacteria, archaea)
- Eukaryotic cells (animals, plants, fungi)

The cell membrane controls what enters and exits the cell...

## Mitochondria

Mitochondria are often called the powerhouse of the cell because...
```

## üì§ Exporting Results

### Convert to PDF
```bash
# Install pandoc (if not installed)
brew install pandoc        # macOS
apt install pandoc         # Linux
choco install pandoc       # Windows

# Convert markdown to PDF
pandoc output/consolidated/master_notes.md -o master_notes.pdf
```

### Import Flashcards to Anki
1. Download [Anki](https://apps.ankiweb.net/)
2. Create new deck
3. File ‚Üí Import ‚Üí Select `flashcards.csv`
4. Configure field mapping if needed

### Share with Others
```bash
# Create zip archive of outputs
zip -r study_materials.zip output/

# Share via email, Google Drive, or cloud storage
```

## üêõ Troubleshooting

### API Key Issues
```
‚ùå ERROR: API keys not configured!
```
**Solution**:
- Verify `.env` file exists in project root
- Check syntax: `KEY=value` (no spaces around `=`)
- Verify keys are valid: test in Anthropic/OpenAI console

### API Rate Limits
```
API request failed: 429 - Rate limit exceeded
```
**Solution**:
- Increase `RETRY_BACKOFF` value
- Add delays between API calls
- Use a free tier API or upgrade plan

### Large Transcript Issues
```
API request failed: 400 - Token limit exceeded
```
**Solution**:
- Reduce `CHUNK_SIZE` (e.g., from 1500 to 1000)
- Pipeline will truncate very long chunks automatically

### Output Permission Errors
```
IOException: Permission denied
```
**Solution**:
- Ensure `output/` directory is writable
- Check file permissions: `chmod 755 output/`
- Verify disk space availability

### Connection Timeout
```
API request failed: Read timed out
```
**Solution**:
- Increase `API_TIMEOUT` value (e.g., 120000 for 2 minutes)
- Check internet connection
- Verify API endpoint URLs are correct

## üìã Pipeline Steps Explained

### 1. Chunking
- **Input**: Raw transcript text
- **Process**: Split into semantic chunks (1000-2000 words each)
- **Output**: `chunks/lesson1_chunks.json`
- **Time**: <1 minute per transcript

### 2. Summarization
- **Input**: Chunks from step 1
- **Process**: Claude API summarizes each chunk (key points, definitions, workflows)
- **Output**: `summaries/chunk_*.json` (one per chunk)
- **Time**: 30-60 seconds per chunk
- **Confidence Tracking**: Marks low-confidence items for review

### 3. Consolidation
- **Input**: All chunk summaries
- **Process**: GPT consolidates into master document with proper formatting
- **Output**: `consolidated/master_notes.md`
- **Time**: 2-5 minutes
- **Quality**: Deduplicates content, resolves contradictions

### 4. Exam Materials
- **Input**: Master notes
- **Process**: Generate flashcards, questions, and revision sheet
- **Output**:
  - `exam_materials/flashcards.csv`
  - `exam_materials/practice_questions.md`
  - `exam_materials/quick_revision.md`
- **Time**: 3-5 minutes

## üéì Use Cases

### Students
- üìö Quickly create study guides from course lectures
- üéØ Generate practice exams to test knowledge
- üíæ Create flashcards for memorization
- üìÑ Get one-page revision sheets before exams

### Educators
- üè´ Auto-generate supplementary materials for courses
- ‚úÖ Create practice questions from lecture transcripts
- üìä Generate standardized study materials
- üîç Review and edit AI-generated content

### Researchers
- üìñ Process seminar transcripts into structured notes
- üîé Extract key concepts and definitions
- üìù Build literature review materials
- üéì Create exam study guides from lecture series

### Content Creators
- üé¨ Transform podcast/video transcripts to written guides
- üìö Create eBooks from transcribed content
- üåê Generate SEO-friendly study materials
- üí° Repurpose existing educational content

## üîç Quality Assurance

The pipeline includes built-in QA measures:

1. **Confidence Scoring**: Each summary is marked as high/medium/low confidence
2. **Manual Review**: Flag low-confidence items for verification
3. **Duplication Detection**: Automatically removes duplicate content during consolidation
4. **Validation**: Cross-references facts between chunks
5. **Format Validation**: Ensures JSON/Markdown output is well-formed

### Review Low-Confidence Items
```json
{
  "chunk_id": "3",
  "confidence": "low",    // ‚ö†Ô∏è Needs review
  "summary": "..."
}
```

## üöÄ Performance Tips

### For Faster Processing
1. **Reduce chunk size**: `CHUNK_SIZE=1000` (faster, less context)
2. **Fewer retries**: `MAX_RETRIES=1` (risky, but faster)
3. **Parallel chunking**: Process multiple files in different runs
4. **Use lighter models**: Consider using cheaper GPT models

### For Better Quality
1. **Larger chunks**: `CHUNK_SIZE=2000` (better context)
2. **More retries**: `MAX_RETRIES=5` (handles transient errors)
3. **Claude model**: Claude is better for summarization than GPT
4. **Manual review**: Always review flagged items

## üìä Cost Estimation

**Approximate API costs** (as of Nov 2024):

For a 50-page transcript (‚âà8000 chunks):

| Step | Model | Input Tokens | Output Tokens | Est. Cost |
|------|-------|-------------|---------------|-----------|
| Chunking | Local | 0 | 0 | Free |
| Summarize | Claude | 300K | 50K | ~$1.50 |
| Consolidate | GPT-4o | 100K | 50K | ~$0.50 |
| Exam Materials | GPT-4o | 50K | 100K | ~$0.30 |
| **Total** | - | - | - | ~$2.30 |

*Prices may vary; check current API pricing.*

## ü§ù Contributing

Contributions welcome! Areas for improvement:
- [ ] Embedding-based vector search
- [ ] Web UI for interactive editing
- [ ] PDF generation integration
- [ ] Support for audio transcription
- [ ] Multi-language support
- [ ] Database for storing results

## üìÑ License

MIT License - See LICENSE file for details

## üÜò Support

- **Documentation**: See docs/ directory and guides in this README
- **Issues**: Report bugs via GitHub Issues
- **Discussion**: Ask questions in GitHub Discussions
- **API Help**:
  - [Anthropic Documentation](https://docs.anthropic.com)
  - [OpenAI Documentation](https://platform.openai.com/docs)

## üéâ Acknowledgments

Built with:
- [Anthropic Claude API](https://www.anthropic.com/claude)
- [OpenAI GPT-4o](https://openai.com/api)
- [OkHttp](https://square.github.io/okhttp/)
- [Jackson](https://github.com/FasterXML/jackson)

---

**Made with ‚ù§Ô∏è for students and educators**

Transform your transcripts. Master your subjects. Ace your exams. üöÄ
